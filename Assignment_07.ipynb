{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a724235",
   "metadata": {},
   "source": [
    "# Hugging Face Text-to-Speech (TTS) Model Demo\n",
    "\n",
    "This notebook demonstrates the exact step-by-step process from the assignment requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install required packages (run in terminal or notebook)\n",
    "# pip install transformers torch IPython soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11993419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import required libraries\n",
    "from transformers import VitsModel, AutoTokenizer\n",
    "import torch\n",
    "from IPython.display import Audio\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac852928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clone and load the pre-trained TTS model from Hugging Face\n",
    "model = VitsModel.from_pretrained(\"facebook/mms-tts-vie\")  # You may replace this with any compatible TTS model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-vie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare input text\n",
    "text = \"Xin chào anh em đến với bài tập của khoá AI Application Engineer\"  # Example text in Vietnamese\n",
    "print(f\"Input text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e10cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(\"Text tokenized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89146f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform inference to generate the waveform\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs).waveform\n",
    "    \n",
    "print(f\"Waveform shape: {output.shape}\")\n",
    "print(f\"Duration: {output.shape[1] / model.config.sampling_rate:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Play the generated audio in Jupyter Notebook\n",
    "Audio(output.numpy(), rate=model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save audio to file (requires soundfile)\n",
    "sf.write('output.wav', output.numpy().squeeze(), model.config.sampling_rate)\n",
    "print(\"Audio saved as 'output.wav'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
